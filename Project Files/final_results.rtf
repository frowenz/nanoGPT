{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww25640\viewh16340\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Config: train_shakespeare_char.py\
File: train_float32.py\
Total training time: 239.97 seconds\
Maxmum amount of memory used: 3.20 GB\
\
Final loss: 0.8247\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_float32.py\
Total training time: 459.59 seconds\
Maxmum amount of memory used: 5.83 GB\
\
Final loss: 0.5426\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_float32.py\
Total training time: 529.70 seconds\
Maxmum amount of memory used: 5.94 GB\
\
Final loss: 0.3195\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_float32.py\
Total training time: 424.55 seconds\
Maxmum amount of memory used: 5.47 GB\
\
Final loss: 0.3751\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char.py\
File: train_batch.py\
Total training time: 104.26 seconds\
Maxmum amount of memory used: 1.02 GB\
\
Final loss: 1.1896\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_batch.py\
Total training time: 157.54 seconds\
Maxmum amount of memory used: 1.90 GB\
\
Final loss: 1.0484\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_batch.py\
Total training time: 179.93 seconds\
Maxmum amount of memory used: 1.92 GB\
\
Final loss: 1.3644\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_batch.py\
Total training time: 166.13 seconds\
Maxmum amount of memory used: 1.61 GB\
\
Final loss: 1.1355\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char.py\
File: train_bfloat.py\
Total training time: 150.99 seconds\
Maxmum amount of memory used: 1.82 GB\
\
Final loss: 0.8209\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_bfloat.py\
Total training time: 262.45 seconds\
Maxmum amount of memory used: 3.71 GB\
\
Final loss: 0.5431\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_bfloat.py\
Total training time: 304.39 seconds\
Maxmum amount of memory used: 3.95 GB\
\
Final loss: 0.3002\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_bfloat.py\
Total training time: 265.06 seconds\
Maxmum amount of memory used: 3.53 GB\
\
Final loss: 0.3750\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char.py\
File: train_float16.py\
Total training time: 157.77 seconds\
Maxmum amount of memory used: 2.04 GB\
\
Final loss: 0.8079\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_float16.py\
Total training time: 260.81 seconds\
Maxmum amount of memory used: 3.71 GB\
\
Final loss: 0.5450\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_float16.py\
Total training time: 312.25 seconds\
Maxmum amount of memory used: 3.95 GB\
\
Final loss: 0.3112\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_float16.py\
Total training time: 265.74 seconds\
Maxmum amount of memory used: 3.53 GB\
\
Final loss: 0.3733\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char.py\
File: train_sgd.py\
Total training time: 228.39 seconds\
Maxmum amount of memory used: 2.76 GB\
\
Final loss: 2.5818\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_sgd.py\
Total training time: 449.02 seconds\
Maxmum amount of memory used: 5.38 GB\
\
Final loss: 2.5865\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_sgd.py\
Total training time: 519.50 seconds\
Maxmum amount of memory used: 5.72 GB\
\
Final loss: 2.5349\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_sgd.py\
Total training time: 423.20 seconds\
Maxmum amount of memory used: 5.37 GB\
\
Final loss: 2.5683\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char.py\
File: train_gradient_accumulation.py\
Total training time: 229.22 seconds\
Maxmum amount of memory used: 0.87 GB\
\
Final loss: 0.8288\
Model Config:Layers: 6\
Embeddings: 384\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_context.py\
File: train_gradient_accumulation.py\
Total training time: 375.62 seconds\
Maxmum amount of memory used: 1.55 GB\
\
Final loss: 0.5513\
Model Config:Layers: 6\
Embeddings: 384\
Context: 512\
--------------------------\
Config: train_shakespeare_char_double_embeddings.py\
File: train_gradient_accumulation.py\
Total training time: 417.97 seconds\
Maxmum amount of memory used: 2.11 GB\
\
Final loss: 0.3222\
Model Config:Layers: 6\
Embeddings: 768\
Context: 256\
--------------------------\
Config: train_shakespeare_char_double_layers.py\
File: train_gradient_accumulation.py\
Total training time: 396.46 seconds\
Maxmum amount of memory used: 1.68 GB\
\
Final loss: 0.3914\
Model Config:Layers: 12\
Embeddings: 384\
Context: 256\
--------------------------\
}